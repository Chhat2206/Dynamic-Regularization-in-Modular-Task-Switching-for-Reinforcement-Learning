# RL-in-GYM
RQ1: How do different regularization techniques impact the performance and knowledge retention of a DQN agent under rapid task switching in the Acrobot environment, particularly when exposed to state noise?

RQ2: How does combining the promising regularization techniques with parameter noise influence the learning stability and adaptability of a modular DQN agent under rapid task switching and stochastic state noise?
